{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Preprocessing**\n",
    "\n",
    "This notebook describes the entire process of **preprocessing MODIS and ERA5 Land (NetCDF) data** and preparing it for **machine learning model training**. The main objective is to generate a dataset where each row represents a specific region and year, with monthly aggregated values of relevant environmental variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.transform import rowcol\n",
    "from rasterio.warp import transform\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import xarray as xr\n",
    "\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MODIS Data Preprocessing and Preparation for Model Training**\n",
    "\n",
    "This notebook outlines the process of **preprocessing MODIS data** and **preparing it for machine learning model training**. The process is divided into three main steps:\n",
    "\n",
    "1. **Generating Threshold-Filtered TIF Files**  \n",
    "2. **Extracting Sample Points from CropMap**  \n",
    "3. **Extracting Multi Values to Points**\n",
    "\n",
    "The goal is to create a dataset where each region contains monthly weighted average values of various MODIS indicators (e.g., NDVI, EVI, LST) for use in crop yield estimation and other analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Generating Threshold-Filtered TIF Files**\n",
    "\n",
    "The first step involves generating **threshold-filtered TIF files** by counting the number of crop pixels within each MODIS grid cell. A new TIF file is created where each pixel value represents the number of crop pixels in the corresponding MODIS grid cell.\n",
    "\n",
    "#### **Steps**:\n",
    "1. Load the CropMap data and MODIS grid information.\n",
    "2. Count the number of crop pixels within each MODIS grid cell for different resolutions (250m, 500m, 1000m).\n",
    "3. Create a new TIF file where each pixel value represents the number of crop pixels.\n",
    "\n",
    "#### **Result**:\n",
    "- A set of **threshold-filtered TIF files** for different MODIS resolutions (250m, 500m, 1000m), which will be used in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_crop_pixels_in_grid(modis_path, cropmap_path, crop_type, output_path, grid_size=1000):\n",
    "    # Read MODIS transform and dimensions\n",
    "    with rasterio.open(modis_path) as modis_src:\n",
    "        modis_transform = modis_src.transform\n",
    "        modis_crs = modis_src.crs\n",
    "        modis_width = modis_src.width\n",
    "        modis_height = modis_src.height\n",
    "\n",
    "    # Read CropMap data\n",
    "    with rasterio.open(cropmap_path) as cropmap_src:\n",
    "        cropmap_data = cropmap_src.read(1)\n",
    "        cropmap_transform = cropmap_src.transform\n",
    "        cropmap_crs = cropmap_src.crs\n",
    "\n",
    "    # Ensure CRS match\n",
    "    if cropmap_crs != modis_crs:\n",
    "        raise ValueError(\"CRS of CropMap and MODIS data do not match.\")\n",
    "    \n",
    "    # Calculate the new dimensions for 250m grid based on MODIS dimensions\n",
    "    new_width = modis_width\n",
    "    new_height = modis_height\n",
    "    \n",
    "    # Create an array to store the counts of crop_type pixels\n",
    "    grid_counts = np.zeros((new_height, new_width), dtype=np.uint16)\n",
    "    \n",
    "    # Iterate over the MODIS grid with tqdm for progress tracking\n",
    "    for i in tqdm(range(new_height), desc=\"Processing rows\"):\n",
    "        for j in range(new_width):\n",
    "            # Calculate the coordinates of the MODIS pixel\n",
    "            modis_x, modis_y = modis_transform * (j, i)\n",
    "            \n",
    "            # Find the corresponding window in the CropMap\n",
    "            col_off, row_off = ~cropmap_transform * (modis_x, modis_y)\n",
    "            col_off = int(col_off)\n",
    "            row_off = int(row_off)\n",
    "            \n",
    "            # Define the window size in CropMap pixels\n",
    "            window_size = grid_size // 10\n",
    "            window = cropmap_data[\n",
    "                row_off:row_off + window_size,\n",
    "                col_off:col_off + window_size\n",
    "            ]\n",
    "            \n",
    "            # Count the number of pixels with the specified crop_type\n",
    "            grid_counts[i, j] = np.sum(window == crop_type)\n",
    "    \n",
    "    # Define the new transform for the 250m resolution based on MODIS transform\n",
    "    new_transform = modis_transform\n",
    "    \n",
    "    # Write the new raster file with 250m resolution\n",
    "    with rasterio.open(\n",
    "        output_path, 'w', driver='GTiff', height=new_height,\n",
    "        width=new_width, count=1, dtype=grid_counts.dtype,\n",
    "        crs=modis_crs, transform=new_transform\n",
    "    ) as dst:\n",
    "        dst.write(grid_counts, 1)\n",
    "\n",
    "\n",
    "# Paths to your raster files\n",
    "modis_path = '/home/sehoon/Desktop/Sehoon/crop_yield/data/MODIS/LST/MODIS_LST_Ukraine_2010-03-22_2.tif'\n",
    "cropmap_path = '/home/sehoon/Desktop/Sehoon/crop_yield/data/EU_CropMap_22_v1_stratum_UA-HR.tif'\n",
    "crop_type = 211\n",
    "output_path = '/home/sehoon/Desktop/Sehoon/crop_yield/data/cropmap/wheat/1000m.tif'\n",
    "\n",
    "count_crop_pixels_in_grid(modis_path, cropmap_path, crop_type, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Extracting Sample Points from CropMap**\n",
    "\n",
    "In this step, sample points are extracted from the **threshold-filtered TIF files** generated in Step 1 based on specific regions and resolutions. Each sample point includes the following information:\n",
    "\n",
    "- **`crop_ratio`**: The proportion of the MODIS pixel covered by the crop.\n",
    "- **`overlap_ratio`**: The ratio of the MODIS pixel area that overlaps with the region polygon.\n",
    "\n",
    "#### **Steps**:\n",
    "1. Load the threshold-filtered TIF files and region polygons (GeoJSON format).\n",
    "2. For each region, extract the MODIS grid cells that overlap with the region.\n",
    "3. Calculate `crop_ratio` and `overlap_ratio` for each grid cell.\n",
    "4. Save the extracted sample points as CSV files for each region.\n",
    "\n",
    "#### **Result**:\n",
    "- CSV files containing **sample points with `crop_ratio` and `overlap_ratio`** for each region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overlap(region_polygon, pixel_geometry):\n",
    "    \"\"\"Calculate the overlap ratio between a pixel and the region polygon.\"\"\"\n",
    "    intersection_area = region_polygon.intersection(pixel_geometry).area\n",
    "    pixel_area = pixel_geometry.area\n",
    "    return intersection_area / pixel_area\n",
    "\n",
    "def process_region_with_overlap(region, land_cover_map, output_dir, resolution):\n",
    "    region_geometry = [region['geometry']]\n",
    "    region_name = region['name']\n",
    "    \n",
    "    with rasterio.open(land_cover_map) as src:\n",
    "        try:\n",
    "            out_image, out_transform = mask(src, region_geometry, crop=False)\n",
    "        except ValueError:\n",
    "            return f\"Region {region_name} does not overlap with the land cover map.\"\n",
    "\n",
    "    # Consider all valid pixels (non-masked)\n",
    "    rows, cols = np.where(out_image[0] > 0)\n",
    "    \n",
    "    if rows.size == 0:\n",
    "        return f\"No overlapping pixels found for region {region_name}.\"\n",
    "\n",
    "    crop_ratios = []\n",
    "    overlap_ratios = []\n",
    "\n",
    "    for row, col in zip(rows, cols):\n",
    "        pixel_value = out_image[0, row, col]\n",
    "        crop_ratio = pixel_value / ((resolution / 10) ** 2)\n",
    "        \n",
    "        # Get the four corner coordinates of the pixel\n",
    "        x_min, y_max = rasterio.transform.xy(out_transform, row, col, offset='ul')\n",
    "        x_max, y_min = rasterio.transform.xy(out_transform, row, col, offset='lr')\n",
    "        \n",
    "        # Create a box representing the pixel\n",
    "        pixel_box = box(x_min, y_min, x_max, y_max)\n",
    "        \n",
    "        overlap_ratio = calculate_overlap(region_geometry[0], pixel_box)\n",
    "        \n",
    "        crop_ratios.append(crop_ratio)\n",
    "        overlap_ratios.append(overlap_ratio)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'idx_x': rows,\n",
    "        'idx_y': cols,\n",
    "        'crop_ratio': crop_ratios,\n",
    "        'overlap_ratio': overlap_ratios\n",
    "    })\n",
    "\n",
    "    safe_region_name = \"\".join([c if c.isalnum() else \"_\" for c in region_name])\n",
    "    output_file = os.path.join(output_dir, f\"{safe_region_name}.csv\")\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    return f\"Saved region {region_name} to {output_file}\"\n",
    "\n",
    "def extract_sample_points_by_region_with_overlap(land_cover_map, region_file, output_dir, resolution, num_cpus=1):\n",
    "    with rasterio.open(land_cover_map) as src:\n",
    "        crs = src.crs\n",
    "\n",
    "    regions = gpd.read_file(region_file)\n",
    "\n",
    "    if regions.crs != crs:\n",
    "        regions = regions.to_crs(crs)\n",
    "\n",
    "    tasks = [\n",
    "        (region, land_cover_map, output_dir, resolution)\n",
    "        for _, region in regions.iterrows()\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    with ProcessPoolExecutor(max_workers=num_cpus) as executor:\n",
    "        future_to_region = {executor.submit(process_region_with_overlap, *task): task[0]['name'] for task in tasks}\n",
    "        for future in tqdm(as_completed(future_to_region), total=len(future_to_region), desc=\"Processing regions\"):\n",
    "            region_name = future_to_region[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "            except Exception as exc:\n",
    "                results.append(f'{region_name} generated an exception: {exc}')\n",
    "\n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n",
    "resolution = 1000\n",
    "\n",
    "# Example usage\n",
    "land_cover_map = f'/home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/{resolution}m/{resolution}m.tif'\n",
    "region_file = '/home/sehoon/Desktop/Sehoon/crop_yield/data/ua.json'\n",
    "output_dir = f'/home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/{resolution}m'\n",
    "num_cpus = 12\n",
    "\n",
    "extract_sample_points_by_region_with_overlap(land_cover_map, region_file, output_dir, resolution, num_cpus=num_cpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Extracting Multi Values to Points**\n",
    "\n",
    "The final step involves extracting **MODIS indicator values** for the sample points and calculating the **monthly weighted average values** using the `crop_ratio` and `overlap_ratio` as weights.\n",
    "\n",
    "#### **Steps**:\n",
    "1. Load the sample points (CSV files) and apply thresholds to filter the data.\n",
    "2. For each MODIS file (NDVI, EVI, LST, etc.), extract the values corresponding to the sample points.\n",
    "3. Calculate the weighted average of the MODIS values using `crop_ratio * overlap_ratio` as weights.\n",
    "4. Save the final results as yearly CSV files, where each file contains the monthly weighted average values for each region.\n",
    "\n",
    "#### **Result**:\n",
    "- Yearly CSV files with **monthly weighted average MODIS indicator values** (`NDVI`, `EVI`, `LST_Day`, `LST_Night`, etc.) for each region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing year 2010: 100%|██████████| 8/8 [00:21<00:00,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame for year 2010:\n",
      "                 region_name  year  month   LST_Night       LAI       EVI  \\\n",
      "0  Avtonomna_Respublika_Krym  2010      4  277.020871  0.054268  0.295739   \n",
      "1                  Cherkaska  2010      4  277.354322  0.022917  0.206472   \n",
      "2               Chernihivska  2010      4  276.693037  0.019556  0.204409   \n",
      "3               Chernivetska  2010      4  272.585667  0.040966  0.274846   \n",
      "4            Dnipropetrovska  2010      4  277.310531  0.021609  0.201053   \n",
      "\n",
      "       FPAR     LST_Day      NDVI  \n",
      "0  0.191749  288.390788  0.472691  \n",
      "1  0.106383  297.213135  0.376571  \n",
      "2  0.098242  293.648550  0.362573  \n",
      "3  0.164644  296.100335  0.461532  \n",
      "4  0.109640  296.909267  0.398972  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing year 2011: 100%|██████████| 8/8 [00:22<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame for year 2011:\n",
      "                 region_name  year  month      NDVI       EVI      FPAR  \\\n",
      "0  Avtonomna_Respublika_Krym  2011      7  0.284149  0.174652  0.118545   \n",
      "1                  Cherkaska  2011      7  0.572646  0.400503  0.257863   \n",
      "2               Chernihivska  2011      7  0.584747  0.382728  0.249903   \n",
      "3               Chernivetska  2011      7  0.557559  0.393830  0.250263   \n",
      "4            Dnipropetrovska  2011      7  0.513674  0.348113  0.219681   \n",
      "\n",
      "    LST_Night       LAI     LST_Day  \n",
      "0  291.940660  0.027370  311.731868  \n",
      "1  289.833573  0.101425  301.494555  \n",
      "2  284.324792  0.092672  298.570866  \n",
      "3  288.560554  0.093034  301.267216  \n",
      "4  291.165493  0.059155  305.046409  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing year 2012: 100%|██████████| 8/8 [00:22<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame for year 2012:\n",
      "                 region_name  year  month     LST_Day      NDVI      FPAR  \\\n",
      "0  Avtonomna_Respublika_Krym  2012      9  306.511593  0.219347  0.075171   \n",
      "1                  Cherkaska  2012      9  297.159773  0.370955  0.141719   \n",
      "2               Chernihivska  2012      9  291.683432  0.443036  0.181806   \n",
      "3               Chernivetska  2012      9  298.581618  0.379699  0.147001   \n",
      "4            Dnipropetrovska  2012      9  299.301731  0.406030  0.126545   \n",
      "\n",
      "        EVI       LAI   LST_Night  \n",
      "0  0.114702  0.012742  286.216437  \n",
      "1  0.191454  0.027540  282.871832  \n",
      "2  0.244857  0.037583  280.589584  \n",
      "3  0.200421  0.028400  284.765430  \n",
      "4  0.201901  0.020988  283.838254  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing year 2013: 100%|██████████| 8/8 [00:22<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame for year 2013:\n",
      "                 region_name  year  month     LST_Day       LAI   LST_Night  \\\n",
      "0  Avtonomna_Respublika_Krym  2013      3  238.001941  0.016597  245.701934   \n",
      "1                  Cherkaska  2013      3  275.540719  0.010313  238.161688   \n",
      "2               Chernihivska  2013      3  219.545613  0.002679  261.850916   \n",
      "3               Chernivetska  2013      3  198.631091  0.002754  223.844159   \n",
      "4            Dnipropetrovska  2013      3  271.127413  0.012325  242.436633   \n",
      "\n",
      "       FPAR      NDVI       EVI  \n",
      "0  0.087377  0.361954  0.199380  \n",
      "1  0.061072  0.283694  0.130060  \n",
      "2  0.018717  0.094347  0.039663  \n",
      "3  0.017468  0.113249  0.063881  \n",
      "4  0.077336  0.337987  0.160341  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing year 2014: 100%|██████████| 8/8 [00:22<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame for year 2014:\n",
      "                 region_name  year  month      NDVI   LST_Night      FPAR  \\\n",
      "0  Avtonomna_Respublika_Krym  2014      6  0.339748  286.245519  0.128087   \n",
      "1                  Cherkaska  2014      6  0.597146  285.885467  0.264085   \n",
      "2               Chernihivska  2014      6  0.593728  284.529625  0.250405   \n",
      "3               Chernivetska  2014      6  0.581566  286.457495  0.259508   \n",
      "4            Dnipropetrovska  2014      6  0.504673  285.991889  0.204881   \n",
      "\n",
      "        LAI     LST_Day       EVI  \n",
      "0  0.030129  300.910333  0.203135  \n",
      "1  0.103969  297.722709  0.452097  \n",
      "2  0.094159  294.862033  0.452705  \n",
      "3  0.094077  295.858274  0.423990  \n",
      "4  0.052854  300.900384  0.338076  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing year 2015: 100%|██████████| 8/8 [00:22<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame for year 2015:\n",
      "                 region_name  year  month       EVI      FPAR     LST_Day  \\\n",
      "0  Avtonomna_Respublika_Krym  2015      8  0.156660  0.111057  310.273158   \n",
      "1                  Cherkaska  2015      8  0.256729  0.201813  303.783019   \n",
      "2               Chernihivska  2015      8  0.297827  0.219989  300.031213   \n",
      "3               Chernivetska  2015      8  0.221689  0.183092  294.622133   \n",
      "4            Dnipropetrovska  2015      8  0.205001  0.151894  305.047263   \n",
      "\n",
      "       NDVI       LAI   LST_Night  \n",
      "0  0.273591  0.021976  290.383100  \n",
      "1  0.410294  0.057373  287.119084  \n",
      "2  0.447487  0.065680  286.100412  \n",
      "3  0.368661  0.046950  287.759205  \n",
      "4  0.365802  0.030006  288.117110  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing year 2016: 100%|██████████| 8/8 [00:22<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame for year 2016:\n",
      "                 region_name  year  month      NDVI   LST_Night     LST_Day  \\\n",
      "0  Avtonomna_Respublika_Krym  2016      8  0.255625  290.569339  306.688834   \n",
      "1                  Cherkaska  2016      8  0.429905  287.145736  301.975227   \n",
      "2               Chernihivska  2016      8  0.510998  284.972419  298.726701   \n",
      "3               Chernivetska  2016      8  0.414750  285.864620  305.483404   \n",
      "4            Dnipropetrovska  2016      8  0.352424  289.471672  307.388621   \n",
      "\n",
      "       FPAR       LAI       EVI  \n",
      "0  0.095959  0.018313  0.141210  \n",
      "1  0.209045  0.058822  0.257901  \n",
      "2  0.238151  0.075495  0.321677  \n",
      "3  0.194165  0.052631  0.254148  \n",
      "4  0.142658  0.027229  0.189086  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing year 2017: 100%|██████████| 8/8 [00:22<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame for year 2017:\n",
      "                 region_name  year  month   LST_Night       EVI       LAI  \\\n",
      "0  Avtonomna_Respublika_Krym  2017      7  291.507779  0.145896  0.021356   \n",
      "1                  Cherkaska  2017      7  289.378200  0.387703  0.099827   \n",
      "2               Chernihivska  2017      7  287.903875  0.415466  0.109236   \n",
      "3               Chernivetska  2017      7  289.456067  0.407555  0.090002   \n",
      "4            Dnipropetrovska  2017      7  290.228518  0.310517  0.052281   \n",
      "\n",
      "      LST_Day      NDVI      FPAR  \n",
      "0  312.737571  0.248563  0.099990  \n",
      "1  302.668108  0.558479  0.259025  \n",
      "2  299.838481  0.583647  0.264587  \n",
      "3  302.915048  0.551349  0.250761  \n",
      "4  305.687075  0.476866  0.205803  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing year 2018: 100%|██████████| 8/8 [00:22<00:00,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame for year 2018:\n",
      "                 region_name  year  month       EVI     LST_Day      NDVI  \\\n",
      "0  Avtonomna_Respublika_Krym  2018      4  0.283534  303.655030  0.459245   \n",
      "1                  Cherkaska  2018      4  0.210329  301.567371  0.390471   \n",
      "2               Chernihivska  2018      4  0.196253  297.448155  0.355275   \n",
      "3               Chernivetska  2018      4  0.305567  300.340168  0.480178   \n",
      "4            Dnipropetrovska  2018      4  0.232857  303.083339  0.445474   \n",
      "\n",
      "    LST_Night       LAI      FPAR  \n",
      "0  280.667603  0.060715  0.206169  \n",
      "1  281.826619  0.031482  0.129254  \n",
      "2  280.452983  0.023368  0.108690  \n",
      "3  283.692616  0.057918  0.193471  \n",
      "4  281.516797  0.030137  0.136868  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing year 2019: 100%|██████████| 8/8 [00:22<00:00,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame for year 2019:\n",
      "                 region_name  year  month   LST_Night      NDVI       EVI  \\\n",
      "0  Avtonomna_Respublika_Krym  2019     10  277.732837  0.204821  0.093550   \n",
      "1                  Cherkaska  2019     10  260.013648  0.244998  0.100604   \n",
      "2               Chernihivska  2019     10  268.445479  0.292106  0.133153   \n",
      "3               Chernivetska  2019     10  266.966156  0.304722  0.145024   \n",
      "4            Dnipropetrovska  2019     10  275.944428  0.395660  0.179138   \n",
      "\n",
      "        LAI      FPAR     LST_Day  \n",
      "0  0.006408  0.051473  289.582611  \n",
      "1  0.008660  0.066401  290.470543  \n",
      "2  0.011457  0.085897  275.636186  \n",
      "3  0.014778  0.104490  287.520318  \n",
      "4  0.010945  0.082757  281.570641  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing year 2020: 100%|██████████| 8/8 [00:22<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame for year 2020:\n",
      "                 region_name  year  month       LAI   LST_Night     LST_Day  \\\n",
      "0  Avtonomna_Respublika_Krym  2020      3  0.025195  273.186873  291.202239   \n",
      "1                  Cherkaska  2020      3  0.011595  267.880677  290.257205   \n",
      "2               Chernihivska  2020      3  0.018798  260.155069  286.578456   \n",
      "3               Chernivetska  2020      3  0.028243  272.367646  275.304008   \n",
      "4            Dnipropetrovska  2020      3  0.024482  272.240271  292.107088   \n",
      "\n",
      "        EVI      NDVI      FPAR  \n",
      "0  0.206553  0.355833  0.130613  \n",
      "1  0.119179  0.268962  0.065557  \n",
      "2  0.166269  0.320964  0.105280  \n",
      "3  0.219464  0.404030  0.130478  \n",
      "4  0.218628  0.436093  0.134200  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing year 2021: 100%|██████████| 8/8 [00:22<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame for year 2021:\n",
      "                 region_name  year  month      NDVI       EVI       LAI  \\\n",
      "0  Avtonomna_Respublika_Krym  2021     10  0.247953  0.109530  0.009082   \n",
      "1                  Cherkaska  2021     10  0.299400  0.132353  0.011624   \n",
      "2               Chernihivska  2021     10  0.331868  0.162353  0.015800   \n",
      "3               Chernivetska  2021     10  0.267653  0.125817  0.013273   \n",
      "4            Dnipropetrovska  2021     10  0.294104  0.128196  0.009231   \n",
      "\n",
      "      LST_Day      FPAR   LST_Night  \n",
      "0  292.400670  0.070888  277.422827  \n",
      "1  278.464218  0.087205  273.678390  \n",
      "2  284.709661  0.107673  272.975458  \n",
      "3  288.900956  0.102531  273.960574  \n",
      "4  280.973778  0.076316  266.719155  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing year 2022: 100%|██████████| 8/8 [00:21<00:00,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame for year 2022:\n",
      "                 region_name  year  month   LST_Night     LST_Day       EVI  \\\n",
      "0  Avtonomna_Respublika_Krym  2022      4  272.241934  289.991880  0.374076   \n",
      "1                  Cherkaska  2022      4  273.523801  292.947132  0.363869   \n",
      "2               Chernihivska  2022      4  218.314267  271.149041  0.346468   \n",
      "3               Chernivetska  2022      4  264.153967  299.075694  0.292176   \n",
      "4            Dnipropetrovska  2022      4  277.835009  264.816869  0.339889   \n",
      "\n",
      "       NDVI       LAI      FPAR  \n",
      "0  0.551498  0.061489  0.208872  \n",
      "1  0.564801  0.046638  0.169256  \n",
      "2  0.542309  0.044575  0.161627  \n",
      "3  0.485795  0.038295  0.163286  \n",
      "4  0.555445  0.035742  0.149019  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing year 2023: 100%|██████████| 8/8 [00:22<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame for year 2023:\n",
      "                 region_name  year  month       LAI     LST_Day      NDVI  \\\n",
      "0  Avtonomna_Respublika_Krym  2023      5  0.046367  296.347554  0.442948   \n",
      "1                  Cherkaska  2023      5  0.052559  303.894444  0.491472   \n",
      "2               Chernihivska  2023      5  0.068936  302.150935  0.495381   \n",
      "3               Chernivetska  2023      5  0.068123  299.615820  0.521383   \n",
      "4            Dnipropetrovska  2023      5  0.034126  302.181101  0.466210   \n",
      "\n",
      "        EVI      FPAR   LST_Night  \n",
      "0  0.283405  0.154004  280.847640  \n",
      "1  0.329606  0.155615  283.619810  \n",
      "2  0.353171  0.204766  282.078831  \n",
      "3  0.381098  0.180909  282.533250  \n",
      "4  0.283206  0.136105  283.535549  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_and_sum_modis_values_single_csv(modis_file, sample_csv_path, summary_key, crop_threshold=0.0, overlap_threshold=0.0):\n",
    "    # Extract year and month from file path\n",
    "    year, month = os.path.basename(os.path.dirname(os.path.dirname(modis_file))), os.path.basename(os.path.dirname(modis_file))\n",
    "    sample_df = pd.read_csv(sample_csv_path)\n",
    "\n",
    "    # Apply thresholds to filter the data\n",
    "    filtered_df = sample_df[(sample_df['crop_ratio'] >= crop_threshold) & (sample_df['overlap_ratio'] >= overlap_threshold)]\n",
    "\n",
    "    # Check if there are valid points after filtering\n",
    "    if filtered_df.empty:\n",
    "        # print(f\"No valid points found for {os.path.basename(sample_csv_path)} after applying thresholds.\")\n",
    "        return None\n",
    "\n",
    "    idx_x = filtered_df['idx_x'].values\n",
    "    idx_y = filtered_df['idx_y'].values\n",
    "    crop_ratios = filtered_df['crop_ratio'].values\n",
    "    overlap_ratios = filtered_df['overlap_ratio'].values\n",
    "    combined_weights = crop_ratios * overlap_ratios\n",
    "\n",
    "    region_name = os.path.splitext(os.path.basename(sample_csv_path))[0]\n",
    "    summary = {\"region_name\": region_name, \"year\": int(year), \"month\": int(month), summary_key: 0.0}\n",
    "\n",
    "    with rasterio.open(modis_file) as src:\n",
    "        # Read the values from the MODIS file based on the indices\n",
    "        values = src.read(1, masked=True)[idx_x, idx_y]\n",
    "\n",
    "        # Scale the values according to the summary key\n",
    "        if summary_key in [\"NDVI\", \"EVI\"]:\n",
    "            values = values / 12000.0\n",
    "        elif summary_key in [\"LST_Day\", \"LST_Night\"]:\n",
    "            values = values * 0.02\n",
    "        elif summary_key in [\"LAI\", \"FPAR\"]:\n",
    "            values = values / 255.0\n",
    "\n",
    "        # Calculate the weighted average using combined weights\n",
    "        summary[summary_key] = np.sum(values * combined_weights) / np.sum(combined_weights)\n",
    "\n",
    "    return pd.DataFrame([summary])\n",
    "\n",
    "def process_year_month(year, month, base_modis_dir, csv_folder, crop_threshold=0.0, overlap_threshold=0.0):\n",
    "    modis_dir = os.path.join(base_modis_dir, str(year), f\"{month:02d}\")\n",
    "    if not os.path.exists(modis_dir):\n",
    "        print(f\"MODIS directory {modis_dir} does not exist.\")\n",
    "        return None\n",
    "\n",
    "    # Prepare a list of all possible indicators\n",
    "    indicators = [\"LST_Night\", \"NDVI\", \"EVI\", \"LAI\", \"FPAR\", \"LST_Day\"]\n",
    "    all_results = []\n",
    "\n",
    "    for modis_file in os.listdir(modis_dir):\n",
    "        modis_path = os.path.join(modis_dir, modis_file)\n",
    "        if not modis_file.endswith('.tif'):\n",
    "            continue\n",
    "\n",
    "        if \"NDVI\" in modis_file:\n",
    "            sample_points_folder = os.path.join(csv_folder, '250m')\n",
    "            summary_key = \"NDVI\"\n",
    "        elif \"EVI\" in modis_file:\n",
    "            sample_points_folder = os.path.join(csv_folder, '250m')\n",
    "            summary_key = \"EVI\"\n",
    "        elif \"LAI\" in modis_file:\n",
    "            sample_points_folder = os.path.join(csv_folder, '500m')\n",
    "            summary_key = \"LAI\"\n",
    "        elif \"FPAR\" in modis_file:\n",
    "            sample_points_folder = os.path.join(csv_folder, '500m')\n",
    "            summary_key = \"FPAR\"\n",
    "        elif \"LST_Day\" in modis_file:\n",
    "            sample_points_folder = os.path.join(csv_folder, '1000m')\n",
    "            summary_key = \"LST_Day\"\n",
    "        elif \"LST_Night\" in modis_file:\n",
    "            sample_points_folder = os.path.join(csv_folder, '1000m')\n",
    "            summary_key = \"LST_Night\"\n",
    "        else:\n",
    "            print(f\"Skipping unknown MODIS file: {modis_file}\")\n",
    "            continue\n",
    "\n",
    "        csv_files = [os.path.join(sample_points_folder, f) for f in os.listdir(sample_points_folder) if f.endswith('.csv')]\n",
    "\n",
    "        for csv_file in csv_files:\n",
    "            result_df = extract_and_sum_modis_values_single_csv(modis_path, csv_file, summary_key, crop_threshold, overlap_threshold)\n",
    "            if result_df is not None:\n",
    "                all_results.append(result_df)\n",
    "\n",
    "    if all_results:\n",
    "        # Combine all results into a single DataFrame\n",
    "        combined_df = pd.concat(all_results, axis=0).groupby(['region_name', 'year', 'month'], as_index=False).mean()\n",
    "\n",
    "        # Ensure all indicators are present in the final DataFrame\n",
    "        for indicator in indicators:\n",
    "            if indicator not in combined_df.columns:\n",
    "                combined_df[indicator] = np.nan\n",
    "\n",
    "        # print(f\"Processed {year}-{month:02d} DataFrame:\")\n",
    "        # print(combined_df.head())  # 첫 몇 줄 출력\n",
    "        return combined_df\n",
    "    return None\n",
    "\n",
    "def main_parallel(csv_folder, base_modis_dir, output_folder, num_cpus=8, crop_threshold=0.0, overlap_threshold=0.0):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    for year in range(2010, 2024):\n",
    "        year_dfs = []\n",
    "\n",
    "        tasks = [(year, month, base_modis_dir, csv_folder, crop_threshold, overlap_threshold) for month in range(3, 11)]\n",
    "        with ProcessPoolExecutor(max_workers=num_cpus) as executor:\n",
    "            futures = [executor.submit(process_year_month, *task) for task in tasks]\n",
    "            for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Processing year {year}\"):\n",
    "                result_df = future.result()\n",
    "                if result_df is not None:\n",
    "                    year_dfs.append(result_df)\n",
    "\n",
    "        if year_dfs:\n",
    "            final_df = pd.concat(year_dfs, ignore_index=True)\n",
    "            print(f\"Final DataFrame for year {year}:\")\n",
    "            print(final_df.head())  # 연도별 최종 데이터프레임의 첫 몇 줄 출력\n",
    "            final_df.to_csv(os.path.join(output_folder, f'results_{year}.csv'), index=False, na_rep='')\n",
    "\n",
    "# Example usage\n",
    "csv_folder = '/home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat'\n",
    "base_modis_dir = '/home/sehoon/Desktop/Sehoon/crop_yield/data/MODIS/preprocessed'\n",
    "output_folder = '/home/sehoon/Desktop/Sehoon/crop_yield/wheat/MODIS'\n",
    "\n",
    "main_parallel(csv_folder, base_modis_dir, output_folder, num_cpus=12, crop_threshold=0.7, overlap_threshold=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NetCDF Data Preprocessing and Preparation for Model Training**\n",
    "\n",
    "This notebook outlines the process of **preprocessing NetCDF data** and **preparing it for machine learning model training**. The process is divided into two main steps:\n",
    "\n",
    "1. **Extracting Sample Points from CropMap for NetCDF**  \n",
    "2. **Extracting and Averaging NetCDF Values**\n",
    "\n",
    "The goal is to create a dataset where each region contains monthly weighted average values of various NetCDF variables (e.g., temperature, precipitation) for use in crop yield estimation and other analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Extracting Sample Points from CropMap for NetCDF**\n",
    "\n",
    "The first step involves extracting **sample points from CropMap data** based on NetCDF grid cells and regions. Each sample point contains information about the proportion of crop pixels (`crop_ratio`) and the overlap ratio (`overlap_ratio`) between the grid cell and the region polygon.\n",
    "\n",
    "#### **Steps**:\n",
    "1. Load the **NetCDF grid information** (longitude, latitude, resolution).\n",
    "2. Load the **CropMap data** and region polygons (GeoJSON format).\n",
    "3. For each NetCDF grid cell, calculate:\n",
    "   - **`crop_ratio`**: Proportion of the grid cell containing the specified crop.\n",
    "   - **`overlap_ratio`**: Proportion of the grid cell that overlaps with the region polygon.\n",
    "4. Save the extracted sample points as **CSV files**, where each file corresponds to a specific region.\n",
    "\n",
    "#### **Result**:\n",
    "- A set of **CSV files** containing sample points with `crop_ratio` and `overlap_ratio` for each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming region CRS from EPSG:4326 to EPSG:3035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:   4%|▎         | 1/27 [00:56<24:20, 56.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Ivano-Frankivska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Ivano_Frankivska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:   7%|▋         | 2/27 [00:56<09:46, 23.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Zakarpatska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Zakarpatska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  11%|█         | 3/27 [00:57<05:13, 13.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Volynska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Volynska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  15%|█▍        | 4/27 [00:57<03:06,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Vinnytska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Vinnytska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  19%|█▊        | 5/27 [00:58<01:58,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Donetska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Donetska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  22%|██▏       | 6/27 [00:58<01:17,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Zhytomyrska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Zhytomyrska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  26%|██▌       | 7/27 [00:59<00:52,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Luhanska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Luhanska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  30%|██▉       | 8/27 [00:59<00:35,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Kirovohradska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Kirovohradska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  33%|███▎      | 9/27 [01:00<00:28,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Avtonomna Respublika Krym to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Avtonomna_Respublika_Krym.csv\n",
      "Saved region Dnipropetrovska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Dnipropetrovska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  41%|████      | 11/27 [01:01<00:15,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Zaporizka to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Zaporizka.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  44%|████▍     | 12/27 [01:02<00:14,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Kyivska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Kyivska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  48%|████▊     | 13/27 [01:52<03:17, 14.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Lvivska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Lvivska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  56%|█████▌    | 15/27 [01:54<01:33,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Poltavska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Poltavska.csv\n",
      "Saved region Mykolaivska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Mykolaivska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  59%|█████▉    | 16/27 [01:56<01:05,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Rivnenska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Rivnenska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  67%|██████▋   | 18/27 [01:56<00:27,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Ternopilska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Ternopilska.csv\n",
      "Saved region Sumska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Sumska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  70%|███████   | 19/27 [01:58<00:21,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Chernivetska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Chernivetska.csv\n",
      "Saved region Kharkivska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Kharkivska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  85%|████████▌ | 23/27 [01:58<00:03,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Khmelnytska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Khmelnytska.csv\n",
      "Saved region Odeska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Odeska.csv\n",
      "Saved region Cherkaska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Cherkaska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  89%|████████▉ | 24/27 [01:59<00:02,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Khersonska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Khersonska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  93%|█████████▎| 25/27 [02:43<00:22, 11.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Sevastopilska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Sevastopilska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions:  96%|█████████▋| 26/27 [02:46<00:09,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Kyivska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Kyivska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing regions: 100%|██████████| 27/27 [02:47<00:00,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved region Chernihivska to /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Chernihivska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def analyze_tif_with_netcdf(netcdf_info, tif_path, target_value=211):\n",
    "    crs = netcdf_info['crs']\n",
    "    lon_min = netcdf_info['lon_min']\n",
    "    lon_max = netcdf_info['lon_max']\n",
    "    lat_min = netcdf_info['lat_min']\n",
    "    lat_max = netcdf_info['lat_max']\n",
    "    lon_res = netcdf_info['lon_res']\n",
    "    lat_res = netcdf_info['lat_res']\n",
    "\n",
    "    results = []\n",
    "\n",
    "    with rasterio.open(tif_path) as tif:\n",
    "        tif_crs = tif.crs\n",
    "\n",
    "        for lat_index, lat in enumerate(np.arange(lat_min, lat_max, lat_res)):\n",
    "            for lon_index, lon in enumerate(np.arange(lon_min, lon_max, lon_res)):\n",
    "                lon_start, lon_end = lon, lon + lon_res\n",
    "                lat_start, lat_end = lat, lat + lat_res\n",
    "\n",
    "                if tif_crs != crs:\n",
    "                    lon_start, lat_start = transform(crs, tif_crs, [lon_start], [lat_start])\n",
    "                    lon_end, lat_end = transform(crs, tif_crs, [lon_end], [lat_end])\n",
    "                    lon_start, lon_end = lon_start[0], lon_end[0]\n",
    "                    lat_start, lat_end = lat_start[0], lat_end[0]\n",
    "\n",
    "                row_start, col_start = rowcol(tif.transform, lon_start, lat_end)\n",
    "                row_stop, col_stop = rowcol(tif.transform, lon_end, lat_start)\n",
    "\n",
    "                row_start = max(0, row_start)\n",
    "                col_start = max(0, col_start)\n",
    "                row_stop = min(tif.height, row_stop)\n",
    "                col_stop = min(tif.width, col_stop)\n",
    "\n",
    "                if row_stop > row_start and col_stop > col_start:\n",
    "                    window_data = tif.read(1, window=((row_start, row_stop), (col_start, col_stop)))\n",
    "                    target_count = np.sum(window_data == target_value)\n",
    "                    total_count = window_data.size\n",
    "                    ratio = target_count / total_count\n",
    "\n",
    "                    results.append({\n",
    "                        'lat_index': lat_index,\n",
    "                        'lon_index': lon_index,\n",
    "                        'ratio': ratio,\n",
    "                        'geom': box(lon_start, lat_start, lon_end, lat_end)\n",
    "                    })\n",
    "\n",
    "    return results\n",
    "\n",
    "def calculate_polygon_overlap(region, netcdf_results):\n",
    "    points = []\n",
    "    \n",
    "    for result in netcdf_results:\n",
    "        netcdf_pixel = gpd.GeoDataFrame([result], geometry=[result['geom']], crs=region.crs)\n",
    "        intersection = gpd.overlay(netcdf_pixel, region, how='intersection')\n",
    "        \n",
    "        for _, intersected_row in intersection.iterrows():\n",
    "            overlap_ratio = intersected_row['geometry'].area / netcdf_pixel.geometry.area.iloc[0]\n",
    "            points.append({\n",
    "                'idx_x': result['lat_index'],\n",
    "                'idx_y': result['lon_index'],\n",
    "                'crop_ratio': result['ratio'],\n",
    "                'overlap_ratio': overlap_ratio\n",
    "            })\n",
    "    \n",
    "    return points\n",
    "\n",
    "def process_region(region, netcdf_results, tif_crs, output_dir):\n",
    "    region_name = region['name']\n",
    "    region_gdf = gpd.GeoDataFrame([region], geometry='geometry', crs=tif_crs)\n",
    "\n",
    "    # Calculate the overlap between netcdf pixels and the current region\n",
    "    sample_points = calculate_polygon_overlap(region_gdf, netcdf_results)\n",
    "\n",
    "    # Save to CSV with the region name\n",
    "    if sample_points:\n",
    "        sample_points_df = pd.DataFrame(sample_points)\n",
    "        safe_region_name = \"\".join([c if c.isalnum() else \"_\" for c in region_name])\n",
    "        output_file = os.path.join(output_dir, f\"{safe_region_name}.csv\")\n",
    "        sample_points_df.to_csv(output_file, index=False)\n",
    "        return f\"Saved region {region_name} to {output_file}\"\n",
    "    else:\n",
    "        return f\"No overlapping pixels found for region {region_name}\"\n",
    "\n",
    "def create_sample_points(netcdf_info, tif_path, region_file, target_value=211, output_dir='output', max_workers=4):\n",
    "    netcdf_results = analyze_tif_with_netcdf(netcdf_info, tif_path, target_value)\n",
    "    regions = gpd.read_file(region_file)\n",
    "\n",
    "    # TIF 파일의 CRS 확인\n",
    "    with rasterio.open(tif_path) as tif:\n",
    "        tif_crs = tif.crs\n",
    "\n",
    "    # 폴리곤 파일이 TIF 파일의 CRS와 다르면 변환\n",
    "    if regions.crs != tif_crs:\n",
    "        print(f\"Transforming region CRS from {regions.crs} to {tif_crs}\")\n",
    "        regions = regions.to_crs(tif_crs)\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # 병렬 처리를 위해 ProcessPoolExecutor 사용\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {\n",
    "            executor.submit(process_region, region, netcdf_results, tif_crs, output_dir): region['name']\n",
    "            for _, region in regions.iterrows()\n",
    "        }\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing regions\"):\n",
    "            region_name = futures[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                print(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Region {region_name} generated an exception: {e}\")\n",
    "\n",
    "# 예제 사용\n",
    "netcdf_info = {\n",
    "    'crs': 'EPSG:4326',\n",
    "    'lon_min': 22.0,\n",
    "    'lon_max': 40.5,\n",
    "    'lat_min': 44.0,\n",
    "    'lat_max': 52.5,\n",
    "    'lon_res': 0.10000000149011612,\n",
    "    'lat_res': 0.10000000149011612,\n",
    "    'transform': [[0.10, 0.00, 22.00], [0.00,-0.10, 52.50], [0.00, 0.00, 1.00]]\n",
    "}\n",
    "\n",
    "tif_path = '/home/sehoon/Desktop/Sehoon/crop_yield/data/EU_CropMap_22_v1_stratum_UA-HR.tif'\n",
    "region_file = '/home/sehoon/Desktop/Sehoon/crop_yield/data/ua.json'\n",
    "output_dir = '/home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land'\n",
    "\n",
    "create_sample_points(netcdf_info, tif_path, region_file, target_value=211, output_dir=output_dir, max_workers=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Extracting and Averaging NetCDF Values**\n",
    "\n",
    "The second step involves using the **sample points extracted in Step 1** to retrieve values from the NetCDF files and calculate the **monthly weighted average values** using the `crop_ratio` and `overlap_ratio` as weights.\n",
    "\n",
    "#### **Steps**:\n",
    "1. Load the sample points (CSV files) and apply thresholds to filter the data based on `crop_ratio` and `overlap_ratio`.\n",
    "2. Load the **NetCDF data** and extract the values corresponding to the sample points for each time step.\n",
    "3. Calculate the **weighted average** for each variable using the product of `crop_ratio` and `overlap_ratio` as weights.\n",
    "4. Save the final results as **yearly CSV files**, where each file contains the monthly weighted average values for each region.\n",
    "\n",
    "#### **Result**:\n",
    "- Yearly CSV files with **monthly weighted average NetCDF variable values** (e.g., temperature, precipitation) for each region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CSV files: 100%|██████████| 26/26 [00:00<00:00, 44.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Sevastopilska.csv - no valid points with crop_ratio >= 0.03 and overlap_ratio <= 0.7\n",
      "Skipping /home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land/Kyivska.csv - no valid points with crop_ratio >= 0.03 and overlap_ratio <= 0.7\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Luhanska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Kirovohradska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Chernihivska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Lvivska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Zhytomyrska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Vinnytska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Ternopilska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Cherkaska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Avtonomna_Respublika_Krym.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Donetska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Ivano_Frankivska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Mykolaivska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Volynska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Poltavska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Sumska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Zakarpatska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Rivnenska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Khmelnytska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Khersonska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Odeska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Chernivetska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Dnipropetrovska.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Zaporizka.csv\n",
      "Saved results to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land/avg_Kharkivska.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def filter_and_get_indices(csv_path, min_crop_ratio=0.1, max_overlap_ratio=0.7):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # `crop_ratio`가 min_crop_ratio 이상이고 `overlap_ratio`가 max_overlap_ratio 이하인 샘플만 선택\n",
    "    df = df[(df['crop_ratio'] >= min_crop_ratio) & (df['overlap_ratio'] <= max_overlap_ratio)]\n",
    "    \n",
    "    if df.empty:\n",
    "        return None, None, None\n",
    "\n",
    "    idx_x = df['idx_x'].values\n",
    "    idx_y = df['idx_y'].values\n",
    "    crop_ratios = df['crop_ratio'].values\n",
    "    overlap_ratios = df['overlap_ratio'].values\n",
    "\n",
    "    # 최종 가중치 계산 (crop_ratio * overlap_ratio)\n",
    "    final_weights = crop_ratios * overlap_ratios\n",
    "    \n",
    "    return idx_x, idx_y, final_weights\n",
    "\n",
    "def extract_and_average_pixel_values(netcdf_path, lat_indices, lon_indices, weights):\n",
    "    ds = xr.open_dataset(netcdf_path)\n",
    "    data_vars = {var: ds[var].values for var in ds.data_vars}\n",
    "    \n",
    "    results = {var: [] for var in ds.data_vars}\n",
    "    \n",
    "    time_steps = ds.sizes['time']\n",
    "    \n",
    "    for time_step in range(time_steps):\n",
    "        sum_values = {var: 0 for var in ds.data_vars}\n",
    "        valid_count = {var: 0 for var in ds.data_vars}\n",
    "        \n",
    "        for var, data in data_vars.items():\n",
    "            values = data[time_step, lat_indices, lon_indices]\n",
    "            valid_mask = ~np.isnan(values)\n",
    "            weighted_sum = np.sum(values[valid_mask] * weights[valid_mask])\n",
    "            valid_count[var] = np.sum(valid_mask)\n",
    "            sum_values[var] += weighted_sum\n",
    "        \n",
    "        avg_values = {var: (sum_values[var] / np.sum(weights[valid_mask]) if valid_count[var] > 0 else np.nan) for var in ds.data_vars}\n",
    "        \n",
    "        for var in ds.data_vars:\n",
    "            results[var].append(avg_values[var])\n",
    "    \n",
    "    avg_df = pd.DataFrame(results, index=ds['time'].values)\n",
    "    \n",
    "    return avg_df\n",
    "\n",
    "def process_csv_file(csv_file, netcdf_path, output_folder):\n",
    "    lat_indices, lon_indices, weights = filter_and_get_indices(csv_file)\n",
    "    \n",
    "    if lat_indices is None:\n",
    "        return f\"Skipping {csv_file} - no valid points with crop_ratio >= 0.03 and overlap_ratio <= 0.7\"\n",
    "\n",
    "    avg_df = extract_and_average_pixel_values(netcdf_path, lat_indices, lon_indices, weights)\n",
    "    \n",
    "    output_csv_path = os.path.join(output_folder, f'avg_{os.path.basename(csv_file)}')\n",
    "    avg_df.to_csv(output_csv_path)\n",
    "    return f\"Saved results to {output_csv_path}\"\n",
    "\n",
    "def process_all_csv_files_in_folder(folder_path, netcdf_path, output_folder, num_cpus=12):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    csv_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    \n",
    "    tasks = [(csv_file, netcdf_path, output_folder) for csv_file in csv_files]\n",
    "    results = []\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=num_cpus) as executor:\n",
    "        future_to_csv = {executor.submit(process_csv_file, *task): task[0] for task in tasks}\n",
    "        for future in tqdm(as_completed(future_to_csv), total=len(future_to_csv), desc='Processing CSV files'):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Exception for {future_to_csv[future]}: {e}\")\n",
    "    \n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n",
    "# Example usage\n",
    "folder_path = '/home/sehoon/Desktop/Sehoon/crop_yield/sample_points/wheat/ERA5_Land'\n",
    "netcdf_path = '/home/sehoon/Desktop/Sehoon/crop_yield/data/ERA5_Land.nc'\n",
    "output_folder = '/home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land'\n",
    "\n",
    "process_all_csv_files_in_folder(folder_path, netcdf_path, output_folder, num_cpus=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Final Step: Combining MODIS and ERA5 Land Data**\n",
    "\n",
    "The final step involves **combining the preprocessed MODIS and ERA5 Land data** into a single dataset. This merged dataset will be used for further analysis and model training.\n",
    "\n",
    "### **Output Example**:\n",
    "| **region_name** | **year** | **month** | **t2m** | **stl1** | **stl2** | **ssr** | **tp** | **swvl1** | **swvl2** | **NDVI** | **EVI** | **LST_Day** | **LST_Night** |\n",
    "|-----------------|----------|-----------|---------|----------|----------|---------|-------|----------|----------|----------|---------|-------------|---------------|\n",
    "| Ivano_Frankivska         | 2013     | 3         | 2.5     | 1.8      | 1.5      | 450.6   | 0.12  | 0.35     | 0.25     | 0.71     | 0.65    | 300.5       | 290.1         |\n",
    "| Luhanska         | 2013     | 4         | 5.2     | 3.1      | 2.7      | 500.2   | 0.18  | 0.42     | 0.30     | 0.74     | 0.69    | 302.0       | 292.8         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to /home/sehoon/Desktop/Sehoon/crop_yield/wheat/combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "def process_era5_land_csv_file(file_path):\n",
    "    # ERA5 Land 파일 처리\n",
    "    region_name = os.path.splitext(os.path.basename(file_path))[0].split('_')[1]\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert the date to year and month\n",
    "    df['date'] = pd.to_datetime(df['Unnamed: 0'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    \n",
    "    # Rearrange columns and rename them as needed\n",
    "    new_df = df[['year', 'month', 't2m', 'stl1', 'stl2', 'ssr', 'tp', 'swvl1', 'swvl2']]\n",
    "    new_df.insert(0, 'region_name', region_name)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def combine_csv_files(folder_path, is_era5_land=True):\n",
    "    all_data = pd.DataFrame()\n",
    "    \n",
    "    # Iterate over all CSV files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            if is_era5_land:\n",
    "                df = process_era5_land_csv_file(file_path)\n",
    "            else:\n",
    "                df = pd.read_csv(file_path)  # 일반 CSV 파일 읽기\n",
    "            \n",
    "            all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "def process_and_merge_data(era5_land_folder, modis_folder, output_file):\n",
    "    # ERA5 Land 데이터 처리 및 병합\n",
    "    era5_land_data = combine_csv_files(era5_land_folder, is_era5_land=True)\n",
    "    \n",
    "    # MODIS 데이터 처리 및 병합\n",
    "    modis_data = combine_csv_files(modis_folder, is_era5_land=False)\n",
    "    \n",
    "    # 두 데이터프레임 병합\n",
    "    combined_df = pd.merge(era5_land_data, modis_data, on=['region_name', 'year', 'month'])\n",
    "    \n",
    "    # 병합된 데이터 저장\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print(f\"Combined data saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "era5_land_folder = '/home/sehoon/Desktop/Sehoon/crop_yield/wheat/ERA5_Land'  # ERA5 Land CSV 파일들이 있는 폴더 경로\n",
    "modis_folder = '/home/sehoon/Desktop/Sehoon/crop_yield/wheat/MODIS'  # MODIS CSV 파일들이 있는 폴더 경로\n",
    "output_file = '/home/sehoon/Desktop/Sehoon/crop_yield/wheat/combined_data.csv'\n",
    "\n",
    "process_and_merge_data(era5_land_folder, modis_folder, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
